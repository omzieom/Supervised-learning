{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M6 W5 Assignment: NLP\n",
    "\n",
    "Natural language processing (NLP) is an important and rapidly developing part of machine learning. New powerful  models (the so-called transformer type) appear regularly and each new one outperforms the previous one in a fundamental NLP task, such as question-answering, name-entity recognition, etc. However, often simple, classical methods tend to work quite well and are a good first approach to solve many NLP problems.\n",
    "\n",
    "In this assignment, I will work with a famous data set for sentiment analysis, namely the Amazon reviews data set. One place where the data can be found is here: https://www.kaggle.com/bittlingmayer/amazonreviews\n",
    "\n",
    "Tasks for this assignment:\n",
    "\n",
    "1) Create a new feature, called ‘n_tokens’ that counts how many tokens(words) there are in a review. In other words, a feature for the length of a review.  \n",
    "\n",
    "2) Create a new feature, called ‘language’, which detects what is the language of each review. So this feature will have a different value for each row (review) of the data.\n",
    "\n",
    "3) Transform each review into a numeric vector of tokens using a bag-of-words. Use can use the CountVectorizer module from sklearn but limit the maximum number of features to be 1000 to avoid memory issues (you can decrease it further if you still have memory issues). Explore the other parameters of the function as well.\n",
    "\n",
    "4) Using the fitted and transformed vector and the above created features, train a model that predicts the sentiment of a review. Note that this will be a classification problem. Evaluate your model and motivate your choice of a performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "%matplotlib inline\n",
    "\n",
    "import bz2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "from polyglot.detect import Detector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>I haven't buy this, but...: In flames es la n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Would not recommend: I bought this printer tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Former Dune Fan: OK - I am done with Dune. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The trailer fooled me for once.: This film wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Did not like: I did not like this spray and g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review\n",
       "0     2   I haven't buy this, but...: In flames es la n...\n",
       "1     1   Would not recommend: I bought this printer tw...\n",
       "2     1   Former Dune Fan: OK - I am done with Dune. Th...\n",
       "3     1   The trailer fooled me for once.: This film wa...\n",
       "4     1   Did not like: I did not like this spray and g..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "train_file = bz2.BZ2File(\"train.ft.txt.bz2\")\n",
    "\n",
    "#Set seed for repeatability and select a random sample of 50000 lines\n",
    "random.seed(42)\n",
    "line_list = random.sample(train_file.readlines(), k=50000)\n",
    "lines = [x.decode('utf-8') for x in line_list]\n",
    "\n",
    "# Split in two: sentiment and review\n",
    "sentiment = [review.split(\"__label__\")[1][0] for review in lines]\n",
    "reviews = [review.split(\"__label__\")[1][1:]  for review in lines]\n",
    "\n",
    "#Create list with sentiment and reviews\n",
    "newlist = []\n",
    "for i in range(len(sentiment)):\n",
    "    newlist.append([sentiment[i], reviews[i]])\n",
    "\n",
    "#Convert list to DataFrame\n",
    "df = pd.DataFrame(newlist, columns = ['score', 'review'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 2 columns and 50000 rows \n",
      "\n",
      "Missing data:\n",
      " score     0\n",
      "review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "rows, columns = df.shape\n",
    "print('The data has {} columns and {} rows \\n'.format(columns, rows))\n",
    "print('Missing data:\\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(df.score, bins=3)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     50000\n",
       "unique        2\n",
       "top           2\n",
       "freq      25042\n",
       "Name: score, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no missing values in the data and that the data is quite eveny spread between positive (`2`) and negative (`1`) reviews.\n",
    "\n",
    "Let's move to the counting the number of tokens (words) in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_tokens'] = [len(re.findall(r'\\w+', line)) for line in df.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>I haven't buy this, but...: In flames es la n...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Would not recommend: I bought this printer tw...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Former Dune Fan: OK - I am done with Dune. Th...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The trailer fooled me for once.: This film wa...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Did not like: I did not like this spray and g...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>yuck: if one could synthesize all that is bad...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>bland: Larry, as always, displays fine techni...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Devastatingly disappointing: The first two bo...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>DANGEROUS- plastic and wire screen ended up i...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Great tick repellent: For someone who has suf...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  n_tokens\n",
       "0     2   I haven't buy this, but...: In flames es la n...        41\n",
       "1     1   Would not recommend: I bought this printer tw...        71\n",
       "2     1   Former Dune Fan: OK - I am done with Dune. Th...       107\n",
       "3     1   The trailer fooled me for once.: This film wa...       121\n",
       "4     1   Did not like: I did not like this spray and g...        41\n",
       "5     1   yuck: if one could synthesize all that is bad...        38\n",
       "6     1   bland: Larry, as always, displays fine techni...        69\n",
       "7     1   Devastatingly disappointing: The first two bo...       170\n",
       "8     1   DANGEROUS- plastic and wire screen ended up i...       134\n",
       "9     2   Great tick repellent: For someone who has suf...        24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the number of words has been computed and added as a column called `n_tokens` using the above list comprehension. Next let's look at detecting the language of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>I haven't buy this, but...: In flames es la n...</td>\n",
       "      <td>41</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Would not recommend: I bought this printer tw...</td>\n",
       "      <td>71</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Former Dune Fan: OK - I am done with Dune. Th...</td>\n",
       "      <td>107</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The trailer fooled me for once.: This film wa...</td>\n",
       "      <td>121</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Did not like: I did not like this spray and g...</td>\n",
       "      <td>41</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  n_tokens language\n",
       "0     2   I haven't buy this, but...: In flames es la n...        41  Spanish\n",
       "1     1   Would not recommend: I bought this printer tw...        71  English\n",
       "2     1   Former Dune Fan: OK - I am done with Dune. Th...       107  English\n",
       "3     1   The trailer fooled me for once.: This film wa...       121  English\n",
       "4     1   Did not like: I did not like this spray and g...        41  English"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'] = df.review.apply(lambda x: Detector(x, quiet=True).language.name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for rows which have not been recorded as English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              review language\n",
      "0       I haven't buy this, but...: In flames es la neta asì que ...  Spanish\n",
      "493     uihuih: uyytui gyuh k !èyui hjuyuy ihuhui jhihui jhuiytfr...     Zulu\n",
      "621     TRACK LIST: mael Rivera / Traigo De TodoLabel: TicoYear: ...  Spanish\n",
      "720     sadly: lo ascolto è pregiudicato in positivo dalla conosc...  Italian\n",
      "2029    Magnífica recopilación de J. Iglesias: En un artista como...  Spanish\n",
      "...                                                              ...      ...\n",
      "49086   Malo: La calidad de video que da este cable es malisima! ...  Spanish\n",
      "49164   Adoro a Jane Austen: Si bien, son buenas adaptaciones de ...  Spanish\n",
      "49408   \"UN VERDADERO PRINCIPE EN SU SALSA\": Despues de 5 años de...  Spanish\n",
      "49451   Es bueno: Me gusto en cuanto a diseño pero yo estaba acos...  Spanish\n",
      "49553   Excellent: Un excellent livre avec des questions_reponses...   French\n",
      "\n",
      "[123 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', 62):\n",
    "    print(df[df['language'] != 'English'][['review', 'language']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On inspection of the sample above it appears that languages have been recorded accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spanish' 'English' 'Zulu' 'Italian' 'French' 'Portuguese' 'Slovenian'\n",
      " 'un' 'Dutch' 'Volapük' 'Norwegian Nynorsk' 'Polish' 'German']\n"
     ]
    }
   ],
   "source": [
    "#Let's look at unique languages\n",
    "print(df.language.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create a count bag of words vector on the reviews column\n",
    "count_vectorizer = CountVectorizer(stop_words=['english','spanish', 'zulu', 'italian', 'french',\\\n",
    "                                               'portuguese', 'slovenian', 'dutch', 'volapük',\\\n",
    "                                               'norwegian', 'polish', 'german'], max_features=1000)\n",
    "review_counts = count_vectorizer.fit_transform(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  12  15  20  30  50  able  about  absolutely  ...  wrong  wrote  \\\n",
       "0   0    0   0   0   0   0   0     0      0           0  ...      0      0   \n",
       "1   0    0   0   0   0   0   0     0      0           0  ...      0      0   \n",
       "2   0    0   0   0   0   0   0     0      0           0  ...      0      0   \n",
       "3   0    0   0   0   0   0   0     0      1           0  ...      0      0   \n",
       "4   0    0   0   0   0   0   0     0      0           0  ...      0      0   \n",
       "\n",
       "   year  years  yes  yet  you  young  your  yourself  \n",
       "0     0      0    0    0    0      0     0         0  \n",
       "1     0      1    0    0    1      0     0         0  \n",
       "2     0      0    0    0    0      0     3         0  \n",
       "3     0      0    0    0    0      0     0         0  \n",
       "4     0      0    0    0    0      0     0         0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframe with review counts\n",
    "count_df = pd.DataFrame(review_counts.A, columns=count_vectorizer.get_feature_names())\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>I haven't buy this, but...: In flames es la n...</td>\n",
       "      <td>41</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Would not recommend: I bought this printer tw...</td>\n",
       "      <td>71</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Former Dune Fan: OK - I am done with Dune. Th...</td>\n",
       "      <td>107</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The trailer fooled me for once.: This film wa...</td>\n",
       "      <td>121</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Did not like: I did not like this spray and g...</td>\n",
       "      <td>41</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  n_tokens language  \\\n",
       "0     2   I haven't buy this, but...: In flames es la n...        41  Spanish   \n",
       "1     1   Would not recommend: I bought this printer tw...        71  English   \n",
       "2     1   Former Dune Fan: OK - I am done with Dune. Th...       107  English   \n",
       "3     1   The trailer fooled me for once.: This film wa...       121  English   \n",
       "4     1   Did not like: I did not like this spray and g...        41  English   \n",
       "\n",
       "   10  100  12  15  20  30  ...  wrong  wrote  year  years  yes  yet  you  \\\n",
       "0   0    0   0   0   0   0  ...      0      0     0      0    0    0    0   \n",
       "1   0    0   0   0   0   0  ...      0      0     0      1    0    0    1   \n",
       "2   0    0   0   0   0   0  ...      0      0     0      0    0    0    0   \n",
       "3   0    0   0   0   0   0  ...      0      0     0      0    0    0    0   \n",
       "4   0    0   0   0   0   0  ...      0      0     0      0    0    0    0   \n",
       "\n",
       "   young  your  yourself  \n",
       "0      0     0         0  \n",
       "1      0     0         0  \n",
       "2      0     3         0  \n",
       "3      0     0         0  \n",
       "4      0     0         0  \n",
       "\n",
       "[5 rows x 1004 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's concat the dataframes\n",
    "df2 = pd.concat([df, count_df], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>language_Portuguese</th>\n",
       "      <th>language_Slovenian</th>\n",
       "      <th>language_Spanish</th>\n",
       "      <th>language_Volapük</th>\n",
       "      <th>language_Zulu</th>\n",
       "      <th>language_un</th>\n",
       "      <th>language_1</th>\n",
       "      <th>language_2</th>\n",
       "      <th>language_3</th>\n",
       "      <th>language_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1016 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  score  n_tokens  10  100  12  15  20  30  50  able  ...  \\\n",
       "0     2        41   0    0   0   0   0   0   0     0  ...   \n",
       "1     1        71   0    0   0   0   0   0   0     0  ...   \n",
       "2     1       107   0    0   0   0   0   0   0     0  ...   \n",
       "3     1       121   0    0   0   0   0   0   0     0  ...   \n",
       "4     1        41   0    0   0   0   0   0   0     0  ...   \n",
       "\n",
       "   language_Portuguese  language_Slovenian  language_Spanish  \\\n",
       "0                    0                   0                 1   \n",
       "1                    0                   0                 0   \n",
       "2                    0                   0                 0   \n",
       "3                    0                   0                 0   \n",
       "4                    0                   0                 0   \n",
       "\n",
       "   language_Volapük  language_Zulu  language_un  language_1  language_2  \\\n",
       "0                 0              0            0           0           0   \n",
       "1                 0              0            0           0           0   \n",
       "2                 0              0            0           0           0   \n",
       "3                 0              0            0           0           0   \n",
       "4                 0              0            0           0           0   \n",
       "\n",
       "   language_3  language_5  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "\n",
       "[5 rows x 1016 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the sake of machine learning let's remove the review column and use get_dummies on the language column\n",
    "df3 = df2.drop('review', axis=1)\n",
    "df3 = pd.get_dummies(df3, columns=['language'], drop_first=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will train a model on this new dataframe which includes the bag of words and new features, `n_tokens` and `language`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The multinomial Naive Bayes classifier is suitable for classification with discrete features\n",
    "#First create test and train data\n",
    "\n",
    "y = df3['score']\n",
    "X = df3.drop('score', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next set up model\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "#define parameter to test\n",
    "params = {\n",
    "    'alpha': np.arange(0.1, 1, 0.2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[6914 1326]\n",
      " [1384 6876]] \n",
      "\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.84      0.84      8240\n",
      "           2       0.84      0.83      0.84      8260\n",
      "\n",
      "    accuracy                           0.84     16500\n",
      "   macro avg       0.84      0.84      0.84     16500\n",
      "weighted avg       0.84      0.84      0.84     16500\n",
      " \n",
      "\n",
      "Best parameters: \n",
      " {'alpha': 0.9000000000000001} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use GridSearchCV to find best parameters\n",
    "grid = GridSearchCV(model, params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "best = grid.best_params_\n",
    "\n",
    "#look at accuracy\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "clf = metrics.classification_report(y_test, y_pred)\n",
    "print('Confusion matrix: \\n', confusion, '\\n')\n",
    "print('Classification report: \\n', clf, '\\n')\n",
    "print('Best parameters: \\n', best, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Looking at the confusion matrix it can be seen that there is almost an equal split with the prediction of positive and negative reviews, which mirrors the equal split of the data.\n",
    "\n",
    "With `alpha` at 0.9 The precision score is 0.84 and is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "### Further work\n",
    "\n",
    "With more processing power I would investigate the performance of other classifiers and build an ensemble. In addition I would like to be able to use the full train data set and use it on the full test data set (not used in this assignment) to see if this would also improve accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
